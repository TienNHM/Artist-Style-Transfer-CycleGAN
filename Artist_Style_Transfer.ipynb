{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artist Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oasd0_T5rS6D",
        "outputId": "3e671679-742f-4d7c-89cf-c4cc42f9b11e"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/HCMUTE/DL/GAN/Artist_Style_Transfer\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HCMUTE/DL/GAN/Artist_Style_Transfer\n",
            "cyclegan-qp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II7pBntHr2cG",
        "outputId": "59a4d007-614e-4996-ac78-527b6bbf9343"
      },
      "source": [
        "!git clone https://github.com/rahulbhalley/cyclegan-qp.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cyclegan-qp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFptMjqHr-ve",
        "outputId": "8b43cfd0-6f41-4037-e724-ac3472307e3c"
      },
      "source": [
        "%cd cyclegan-qp\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HCMUTE/DL/GAN/Artist_Style_Transfer/cyclegan-qp\n",
            "'Artist Style Transfer.ipynb'   data.py\t\t      LICENSE\t    README.md\n",
            " assets\t\t\t        datasets\t      main.py\t    samples\n",
            " checkpoints\t\t        download_dataset.sh   networks.py\n",
            " config.py\t\t        images\t\t      __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-EPSxKAzwBG"
      },
      "source": [
        "!bash download_dataset.sh monet2photo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v92xoxZpKsTS"
      },
      "source": [
        "!bash download_dataset.sh cezanne2photo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvG0ErNzfkT"
      },
      "source": [
        "!bash download_dataset.sh ukiyoe2photo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9pqloUsAw6"
      },
      "source": [
        "!bash download_dataset.sh vangogh2photo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgA9v6GuEu1"
      },
      "source": [
        "MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyxODnJCuGBK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from networks import Generator, Critic\n",
        "from config import *\n",
        "from data import *\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyl-rzHguJWd"
      },
      "source": [
        "####################\n",
        "# Make directories #\n",
        "####################\n",
        "\n",
        "try:\n",
        "    if TRAIN:\n",
        "        # Checkpoint directories\n",
        "        if not os.path.exists(CKPT_DIR):\n",
        "            os.mkdir(CKPT_DIR)\n",
        "        for style in STYLES:\n",
        "            if not os.path.exists(os.path.join(CKPT_DIR, style)):\n",
        "                os.mkdir(os.path.join(CKPT_DIR, style))\n",
        "    else:\n",
        "        # Sample directories\n",
        "        if not os.path.exists(SAMPLE_DIR):\n",
        "            os.mkdir(SAMPLE_DIR)\n",
        "        \n",
        "        for style in STYLES:\n",
        "            if not os.path.exists(os.path.join(SAMPLE_DIR, style)):\n",
        "                os.mkdir(os.path.join(SAMPLE_DIR, style))\n",
        "                # Make three directories\n",
        "                os.mkdir(os.path.join(SAMPLE_DIR, style, OUT_STY_DIR))  # Stylized images here\n",
        "                os.mkdir(os.path.join(SAMPLE_DIR, style, OUT_REC_DIR))  # Reconstructed images here\n",
        "except:\n",
        "    print(\"Directories already exist!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihWgm5nMuPAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80adf0cd-8a70-4be5-e726-f8984ced5b9f"
      },
      "source": [
        "####################\n",
        "# Load the dataset #\n",
        "####################\n",
        "\n",
        "if TRAIN:\n",
        "    # Make experiments reproducible\n",
        "    _ = torch.manual_seed(RANDOM_SEED)\n",
        "    \n",
        "    # Load the datasets\n",
        "    X_set, Y_set = load_data()\n",
        "\n",
        "    # Load infinite data\n",
        "    X_data = get_infinite_X_data(X_set)\n",
        "    Y_data = get_infinite_Y_data(Y_set)\n",
        "\n",
        "    print(\"Loaded dataset\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Details\n",
            "X_set batches: 38\n",
            "Y_set batches: 38\n",
            "\n",
            "Loaded dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoX7nFHuSzn"
      },
      "source": [
        "########################################################\n",
        "# Define device, neural nets, losses, optimizers, etc. #\n",
        "########################################################\n",
        "\n",
        "# Automatic GPU/CPU device placement\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Networks\n",
        "C_X = Critic().to(device)   # Criticizes X data\n",
        "C_Y = Critic().to(device)   # Criticizes Y data\n",
        "G = Generator(upsample=UPSAMPLE).to(device) # Translates X -> Y\n",
        "F = Generator(upsample=UPSAMPLE).to(device) # Translates Y -> X\n",
        "\n",
        "# Losses\n",
        "l1_loss = nn.L1Loss()\n",
        "\n",
        "# Optimizers\n",
        "C_X_optim = optim.Adam(C_X.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "C_Y_optim = optim.Adam(C_Y.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "G_optim =   optim.Adam(G.parameters(),   lr=LR, betas=(BETA1, BETA2))\n",
        "F_optim =   optim.Adam(F.parameters(),   lr=LR, betas=(BETA1, BETA2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpmFDvTEuZU4"
      },
      "source": [
        "###############\n",
        "# Training üß† #\n",
        "###############\n",
        "\n",
        "def train():\n",
        "\n",
        "    # Status\n",
        "    print(\"Begin training!\")\n",
        "\n",
        "    # Load the checkpoints from `BEGIN_ITER`\n",
        "    try:\n",
        "        # Get checkpoint paths\n",
        "        g_model_path =   os.path.join(CKPT_DIR, TRAIN_STYLE, f\"G_{BEGIN_ITER}.pth\")\n",
        "        f_model_path =   os.path.join(CKPT_DIR, TRAIN_STYLE, f\"F_{BEGIN_ITER}.pth\")\n",
        "        c_x_model_path = os.path.join(CKPT_DIR, TRAIN_STYLE, f\"C_X_{BEGIN_ITER}.pth\")\n",
        "        c_y_model_path = os.path.join(CKPT_DIR, TRAIN_STYLE, f\"C_Y_{BEGIN_ITER}.pth\")\n",
        "\n",
        "        # Load parameters from checkpoint paths\n",
        "        G.load_state_dict(torch.load(g_model_path,     map_location=device))\n",
        "        F.load_state_dict(torch.load(f_model_path,     map_location=device))\n",
        "        C_X.load_state_dict(torch.load(c_x_model_path, map_location=device))\n",
        "        C_Y.load_state_dict(torch.load(c_y_model_path, map_location=device))\n",
        "        \n",
        "        # Status\n",
        "        print(f\"Training: Loaded the checkpoints from {BEGIN_ITER}th iteration.\")\n",
        "    except:\n",
        "        # Status\n",
        "        print(f\"Training: Couldn't load the checkpoints from {BEGIN_ITER}th iteration.\")\n",
        "\n",
        "    # Now finally begin training!\n",
        "    for i in range(BEGIN_ITER, END_ITER + 1):\n",
        "        \n",
        "        # Sample safely\n",
        "        x, y = safe_sampling(X_data, Y_data, device)\n",
        "\n",
        "        #################\n",
        "        # Train Critics #\n",
        "        #################\n",
        "\n",
        "        # Update gradient computation:\n",
        "        # ‚àô üëé Generators\n",
        "        # ‚àô üëç Critics\n",
        "        for param in G.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        for param in F.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        for param in C_X.parameters():\n",
        "            param.requires_grad_(True)\n",
        "        for param in C_Y.parameters():\n",
        "            param.requires_grad_(True)\n",
        "\n",
        "        for j in range(2):\n",
        "\n",
        "            # Forward passes:\n",
        "            # ‚àô X -> Y\n",
        "            # ‚àô Y -> X\n",
        "\n",
        "            # Domain translation: X -> Y\n",
        "            with torch.no_grad():\n",
        "                G_x = G(x)      # G(x),     X -> Y\n",
        "            C_Y_G_x = C_Y(G_x)  # Cy(G(x)), fake score\n",
        "            C_y_y = C_Y(y)      # Cy(y),    real score\n",
        "\n",
        "            # Domain translation: Y -> X\n",
        "            with torch.no_grad():\n",
        "                F_y = F(y)      # F(y),     Y -> X\n",
        "            C_X_F_y = C_X(F_y)  # Cx(F(y)), fake score\n",
        "            C_X_x = C_X(x)      # Cx(x),    real score\n",
        "\n",
        "            # Zerofy the gradients\n",
        "            C_X_optim.zero_grad()\n",
        "            C_Y_optim.zero_grad()\n",
        "\n",
        "            # Compute the losses:\n",
        "            # ‚àô QP-div loss (critizing x data),     Y -> X\n",
        "            # ‚àô QP-div loss (critizing y data),     X -> Y\n",
        "\n",
        "            # QP-div loss (critizing x data)\n",
        "            x_loss = C_X_x - C_X_F_y    # real score - fake score\n",
        "            if NORM == \"l1\":\n",
        "                x_norm = LAMBDA * (x - F_y).abs().mean()\n",
        "            elif NORM == \"l2\":\n",
        "                x_norm = LAMBDA * ((x - F_y)**2).mean().sqrt()\n",
        "            x_loss = -x_loss + 0.5 * x_loss**2 / x_norm\n",
        "            x_loss = x_loss.mean()\n",
        "\n",
        "            # QP-div loss (critizing y data)\n",
        "            y_loss = C_y_y - C_Y_G_x    # real score - fake score\n",
        "            if NORM == \"l1\":\n",
        "                y_norm = LAMBDA * (y - G_x).abs().mean()\n",
        "            elif NORM == \"l2\":\n",
        "                y_norm = LAMBDA * ((y - G_x)**2).mean().sqrt()\n",
        "            y_loss = -y_loss + 0.5 * y_loss**2 / y_norm\n",
        "            y_loss = y_loss.mean()\n",
        "\n",
        "            # Total loss\n",
        "            c_loss = x_loss + y_loss\n",
        "\n",
        "            # Compute gradients\n",
        "            c_loss.backward()\n",
        "\n",
        "            # Update the networks\n",
        "            C_Y_optim.step()\n",
        "            C_X_optim.step()\n",
        "\n",
        "        ####################\n",
        "        # Train Generators #\n",
        "        ####################\n",
        "\n",
        "        # Update gradient computation:\n",
        "        # ‚àô üëç Generators\n",
        "        # ‚àô üëé Critics\n",
        "        for param in G.parameters():\n",
        "            param.requires_grad_(True)\n",
        "        for param in F.parameters():\n",
        "            param.requires_grad_(True)\n",
        "        for param in C_X.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        for param in C_Y.parameters():\n",
        "            param.requires_grad_(False)\n",
        "\n",
        "        for j in range(1):\n",
        "\n",
        "            # Forward passes:\n",
        "            # ‚àô X -> Y\n",
        "            # ‚àô Y -> X\n",
        "            # ‚àô X -> Y -> X\n",
        "            # ‚àô Y -> X -> Y\n",
        "\n",
        "            # Domain translation: X -> Y\n",
        "            G_x = G(x)          # G(x),     X -> Y\n",
        "            C_Y_G_x = C_Y(G_x)  # Cy(G(x)), fake score\n",
        "            C_y_y = C_Y(y)      # Cy(y),    real score\n",
        "\n",
        "            # Domain translation: Y -> X\n",
        "            F_y = F(y)          # F(y),     Y -> X\n",
        "            C_X_F_y = C_X(F_y)  # Cx(F(y)), fake score\n",
        "            C_X_x = C_X(x)      # Cx(x),    real score\n",
        "\n",
        "            # Cycle-consistent translations\n",
        "            F_G_x = F(G_x)      # F(G(x)), X -> Y -> X\n",
        "            G_F_y = G(F_y)      # G(F(y)), Y -> X -> Y\n",
        "\n",
        "            # Zerofy the gradients\n",
        "            G_optim.zero_grad()\n",
        "            F_optim.zero_grad()\n",
        "\n",
        "            # Compute the losses:\n",
        "            # ‚àô QP-div loss (critizing x data),     Y -> X\n",
        "            # ‚àô QP-div loss (critizing y data),     X -> Y\n",
        "            # ‚àô Cycle-consistency loss,             || F(G(x)) - x || L1\n",
        "            # ‚àô Cycle-consistency loss,             || G(F(y)) - y || L1\n",
        "            # ‚àô Identity loss,                      || G(x) - y || L1\n",
        "            # ‚àô Identity loss,                      || F(y) - x || L1\n",
        "            \n",
        "            # QP-div losses\n",
        "            x_loss = C_X_x - C_X_F_y        # real score - fake score\n",
        "            y_loss = C_y_y - C_Y_G_x        # real score - fake score\n",
        "            x_loss = x_loss.mean()\n",
        "            y_loss = y_loss.mean()\n",
        "\n",
        "            # Cycle-consistency losses\n",
        "            x_cyc_loss = l1_loss(F_G_x, x)  # || F(G(x)) - x || L1\n",
        "            y_cyc_loss = l1_loss(G_F_y, y)  # || G(F(y)) - y || L1\n",
        "            x_cyc_loss = x_cyc_loss.mean()\n",
        "            y_cyc_loss = y_cyc_loss.mean()\n",
        "            \n",
        "            # Identity losses\n",
        "            x_id_loss = l1_loss(G_x, y)     # || G(x) - y || L1\n",
        "            y_id_loss = l1_loss(F_y, x)     # || F(y) - x || L1\n",
        "            x_id_loss = x_id_loss.mean()\n",
        "            y_id_loss = y_id_loss.mean()\n",
        "\n",
        "            # Total loss\n",
        "            g_loss = x_loss + y_loss\n",
        "            g_loss += CYC_WEIGHT * (x_cyc_loss + y_cyc_loss)\n",
        "            g_loss += ID_WEIGHT * (x_id_loss + y_id_loss)\n",
        "\n",
        "            # Compute gradients\n",
        "            g_loss.backward()\n",
        "\n",
        "            # Update the networks\n",
        "            G_optim.step()\n",
        "            F_optim.step()\n",
        "\n",
        "        #############\n",
        "        # Log stats #\n",
        "        #############\n",
        "\n",
        "        if i % ITERS_PER_LOG == 0:\n",
        "            # Status\n",
        "            print(f\"iter: {i} c_loss: {c_loss} g_loss: {g_loss}\")\n",
        "\n",
        "        if i % ITERS_PER_CKPT == 0:\n",
        "            # Get checkpoint paths\n",
        "            g_model_path =   os.path.join(CKPT_DIR, TRAIN_STYLE, f\"G_{i}.pth\")\n",
        "            f_model_path =   os.path.join(CKPT_DIR, TRAIN_STYLE, f\"F_{i}.pth\")\n",
        "            c_x_model_path = os.path.join(CKPT_DIR, TRAIN_STYLE, f\"C_X_{i}.pth\")\n",
        "            c_y_model_path = os.path.join(CKPT_DIR, TRAIN_STYLE, f\"C_Y_{i}.pth\")\n",
        "\n",
        "            # Save the checkpoints\n",
        "            torch.save(G.state_dict(),   g_model_path)\n",
        "            torch.save(F.state_dict(),   f_model_path)\n",
        "            torch.save(C_X.state_dict(), c_x_model_path)\n",
        "            torch.save(C_Y.state_dict(), c_y_model_path)\n",
        "\n",
        "            # Status\n",
        "            print(f\"Saved checkpoints at {i}th iteration.\")\n",
        "    # Status\n",
        "    print(\"Finished Training!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GdEVCX8uhRx"
      },
      "source": [
        "################\n",
        "# Inference üß† #\n",
        "################\n",
        "\n",
        "def infer(iteration, style, img_name, in_img_dir, out_rec_dir, out_sty_dir, img_size=None):\n",
        "    \n",
        "    print(\"iteration = \", iteration)\n",
        "    # Set neural nets to evaluation mode\n",
        "    G.eval()\n",
        "    F.eval()\n",
        "\n",
        "    # Try loading models from checkpoints at `iteration`\n",
        "    try:\n",
        "        # Get checkpoint paths\n",
        "        g_model_path = os.path.join(CKPT_DIR, style, f\"G_{iteration}.pth\")\n",
        "        f_model_path = os.path.join(CKPT_DIR, style, f\"F_{iteration}.pth\")\n",
        "        \n",
        "        # Load parameters from checkpoint paths\n",
        "        G.load_state_dict(torch.load(g_model_path, map_location=device))\n",
        "        F.load_state_dict(torch.load(f_model_path, map_location=device))\n",
        "        \n",
        "        # Status\n",
        "        print(f\"Inference: Loaded the checkpoints from {iteration}th iteration.\")\n",
        "    except:\n",
        "        # Status\n",
        "        print(f\"Inference: Couldn't load the checkpoints from {iteration}th iteration.\")\n",
        "        raise\n",
        "\n",
        "    # Minor transforms\n",
        "    if img_size == None:\n",
        "        loader = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
        "        ])\n",
        "    else:\n",
        "        loader = transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.CenterCrop(img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
        "        ])\n",
        "\n",
        "    from PIL import Image\n",
        "\n",
        "    def image_loader(image_name):\n",
        "        image = Image.open(image_name)\n",
        "        image = loader(image).unsqueeze(0)  # Add a fake batch dimension\n",
        "        return image.to(device, torch.float)\n",
        "    \n",
        "    # style_a = image_loader(out_img_path)\n",
        "    in_img_path = os.path.join(in_img_dir, img_name)\n",
        "    in_img = image_loader(in_img_path)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        print(\"Stylization\")\n",
        "        sty_img = F(in_img)     # Y -> X\n",
        "        print(\"Reconstruction\")\n",
        "        rec_img = G(sty_img)    # X -> Y\n",
        "    \n",
        "    # WARNING: Please do not change this code snippet with a closed mind. ü§™üëª\n",
        "    only_img_name = img_name.split('.')[0]\n",
        "    img_type = img_name.split('.')[1]\n",
        "\n",
        "    # Set up names\n",
        "    out_sty_name = f\"sty_{only_img_name}_{style}_{iteration}.{img_type}\"\n",
        "    out_rec_name = f\"rec_{only_img_name}_{style}_{iteration}.{img_type}\"\n",
        "    \n",
        "    # Set up paths\n",
        "    sty_path = os.path.join(SAMPLE_DIR, style, out_sty_dir, out_sty_name)\n",
        "    rec_path = os.path.join(SAMPLE_DIR, style, out_rec_dir, out_rec_name)\n",
        "    \n",
        "    # Save image grids\n",
        "    vutils.save_image(sty_img, sty_path, normalize=True)\n",
        "    vutils.save_image(rec_img, rec_path, normalize=True)\n",
        "    \n",
        "    # Status\n",
        "    print(f\"Saved {rec_path}\")\n",
        "    print(f\"Saved {sty_path}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bJmGOHxul1e",
        "outputId": "6f981029-31c0-4998-da53-eda4f43e9440"
      },
      "source": [
        "IMG_NAME = \"demo1.jpg\"\n",
        "INFER_STYLE = \"color\"\n",
        "TRAIN = True\n",
        "BEGIN_ITER = 0\n",
        "END_ITER = 20\n",
        "INFER_ITER = 20\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    if TRAIN:\n",
        "        train()\n",
        "    else:\n",
        "        infer(\n",
        "            iteration=INFER_ITER,\n",
        "            style=INFER_STYLE,\n",
        "            img_name=IMG_NAME,\n",
        "            in_img_dir=IN_IMG_DIR,\n",
        "            out_rec_dir=OUT_REC_DIR,\n",
        "            out_sty_dir=OUT_STY_DIR,\n",
        "            img_size=IMG_SIZE\n",
        "        )\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin training!\n",
            "Training: Couldn't load the checkpoints from 0th iteration.\n",
            "iter: 0 c_loss: 1.2178510427474976 g_loss: 13.638105392456055\n",
            "Saved checkpoints at 0th iteration.\n",
            "iter: 1 c_loss: -0.13216142356395721 g_loss: 12.924322128295898\n",
            "Saved checkpoints at 1th iteration.\n",
            "iter: 2 c_loss: -0.5198467969894409 g_loss: 11.963750839233398\n",
            "Saved checkpoints at 2th iteration.\n",
            "iter: 3 c_loss: -0.6448197960853577 g_loss: 10.734578132629395\n",
            "Saved checkpoints at 3th iteration.\n",
            "iter: 4 c_loss: -0.5911527872085571 g_loss: 10.649738311767578\n",
            "Saved checkpoints at 4th iteration.\n",
            "iter: 5 c_loss: -0.5358226299285889 g_loss: 9.440223693847656\n",
            "Saved checkpoints at 5th iteration.\n",
            "iter: 6 c_loss: -0.3216649889945984 g_loss: 8.386070251464844\n",
            "Saved checkpoints at 6th iteration.\n",
            "iter: 7 c_loss: -0.43390578031539917 g_loss: 8.623525619506836\n",
            "Saved checkpoints at 7th iteration.\n",
            "iter: 8 c_loss: -0.00899609923362732 g_loss: 7.665021896362305\n",
            "Saved checkpoints at 8th iteration.\n",
            "iter: 9 c_loss: -0.9277944564819336 g_loss: 8.797774314880371\n",
            "Saved checkpoints at 9th iteration.\n",
            "iter: 10 c_loss: -1.0305500030517578 g_loss: 7.43509578704834\n",
            "Saved checkpoints at 10th iteration.\n",
            "iter: 11 c_loss: -0.857285737991333 g_loss: 7.3472747802734375\n",
            "Saved checkpoints at 11th iteration.\n",
            "iter: 12 c_loss: -0.2691907584667206 g_loss: 6.779996395111084\n",
            "Saved checkpoints at 12th iteration.\n",
            "iter: 13 c_loss: -0.6615128517150879 g_loss: 7.279688835144043\n",
            "Saved checkpoints at 13th iteration.\n",
            "iter: 14 c_loss: -0.7315434813499451 g_loss: 7.455419540405273\n",
            "Saved checkpoints at 14th iteration.\n",
            "iter: 15 c_loss: -0.5647450685501099 g_loss: 7.089359760284424\n",
            "Saved checkpoints at 15th iteration.\n",
            "iter: 16 c_loss: -0.8899028897285461 g_loss: 6.947590351104736\n",
            "Saved checkpoints at 16th iteration.\n",
            "iter: 17 c_loss: -1.0619173049926758 g_loss: 7.834425926208496\n",
            "Saved checkpoints at 17th iteration.\n",
            "iter: 18 c_loss: -0.6743765473365784 g_loss: 7.864903926849365\n",
            "Saved checkpoints at 18th iteration.\n",
            "iter: 19 c_loss: -0.7689822912216187 g_loss: 7.261453151702881\n",
            "Saved checkpoints at 19th iteration.\n",
            "iter: 20 c_loss: -0.32039764523506165 g_loss: 5.865560054779053\n",
            "Saved checkpoints at 20th iteration.\n",
            "Finished Training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkgIcL27Krwq",
        "outputId": "068d7c23-a219-40a4-a085-b2a4c4aeee22"
      },
      "source": [
        "IMG_NAME = \"img.jpg\"\n",
        "INFER_STYLE = \"color\"\n",
        "TRAIN = False\n",
        "BEGIN_ITER = 0\n",
        "END_ITER = 20\n",
        "INFER_ITER = 20\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    if TRAIN:\n",
        "        train()\n",
        "    else:\n",
        "        infer(\n",
        "            iteration=INFER_ITER,\n",
        "            style=INFER_STYLE,\n",
        "            img_name=IMG_NAME,\n",
        "            in_img_dir=IN_IMG_DIR,\n",
        "            out_rec_dir=OUT_REC_DIR,\n",
        "            out_sty_dir=OUT_STY_DIR,\n",
        "            img_size=IMG_SIZE\n",
        "        )\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration =  20\n",
            "Inference: Loaded the checkpoints from 20th iteration.\n",
            "Stylization\n",
            "Reconstruction\n",
            "Saved samples/color/rec/rec_img_color_20.jpg\n",
            "Saved samples/color/sty/sty_img_color_20.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKKICb4Xy555"
      },
      "source": [
        "Src: https://github.com/rahulbhalley/cyclegan-qp\n",
        "\n",
        "Epochs | Times\n",
        "---- | -----\n",
        "10 | 39m 40s\n",
        "15 | 54m 34s\n",
        "20 | 63m 36s\n",
        "\n",
        "### Loss\n",
        "\n",
        "iter | c_loss | g_loss\n",
        ":---: | :---: | :----:\n",
        "iter: 0 | c_loss: 1.2178510427474976 | g_loss: 13.638105392456055\n",
        "iter: 1 | c_loss: -0.13216142356395721 | g_loss: 12.924322128295898\n",
        "iter: 2 | c_loss: -0.5198467969894409 | g_loss: 11.963750839233398\n",
        "iter: 3 | c_loss: -0.6448197960853577 | g_loss: 10.734578132629395\n",
        "iter: 4 | c_loss: -0.5911527872085571 | g_loss: 10.649738311767578\n",
        "iter: 5 | c_loss: -0.5358226299285889 | g_loss: 9.440223693847656\n",
        "iter: 6 | c_loss: -0.3216649889945984 | g_loss: 8.386070251464844\n",
        "iter: 7 | c_loss: -0.43390578031539917 | g_loss: 8.623525619506836\n",
        "iter: 8 | c_loss: -0.00899609923362732 | g_loss: 7.665021896362305\n",
        "iter: 9 | c_loss: -0.9277944564819336 | g_loss: 8.797774314880371\n",
        "iter: 10 | c_loss: -1.0305500030517578 | g_loss: 7.43509578704834\n",
        "iter: 11 | c_loss: -0.857285737991333 | g_loss: 7.3472747802734375\n",
        "iter: 12 | c_loss: -0.2691907584667206 | g_loss: 6.779996395111084\n",
        "iter: 13 | c_loss: -0.6615128517150879 | g_loss: 7.279688835144043\n",
        "iter: 14 | c_loss: -0.7315434813499451 | g_loss: 7.455419540405273\n",
        "iter: 15 | c_loss: -0.5647450685501099 | g_loss: 7.089359760284424\n",
        "iter: 16 | c_loss: -0.8899028897285461 | g_loss: 6.947590351104736\n",
        "iter: 17 | c_loss: -1.0619173049926758 | g_loss: 7.834425926208496\n",
        "iter: 18 | c_loss: -0.6743765473365784 | g_loss: 7.864903926849365\n",
        "iter: 19 | c_loss: -0.7689822912216187 | g_loss: 7.261453151702881\n",
        "iter: 20 | c_loss: -0.32039764523506165 | g_loss: 5.865560054779053\n"
      ]
    }
  ]
}